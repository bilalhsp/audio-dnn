gilbreth-c002.rcac.purdue.edu
Total tasks: 4
Total tasks per node: 4
CPUs per task: 2
CUDA visible devices: 0,1,2,3
Number of nodes: 1
The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/1.1.2
num_proc        : 2
Process rank: 0
World size: 4
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:326: UserWarning: Device capability of gloo|nccl unknown, assuming `cpu` and `cuda`. You can specify it in `device:backend` format in `init_process_group` call.
  warnings.warn(
Traceback (most recent call last):
  File "../scripts/pretrain_wav2vec2.py", line 133, in <module>
    dist.init_process_group(backend="gloo|nccl")
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 89, in wrapper
num_proc        : 2
Process rank: 1
World size: 4
    func_return = func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1312, in init_process_group
    default_pg, _ = _new_process_group_helper(
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1544, in _new_process_group_helper
    assert backend_str.upper() in Backend._plugins, (
AssertionError: Unknown c10d backend type GLOO|NCCL
num_proc        : 2
Process rank: 2
World size: 4
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:326: UserWarning: Device capability of gloo|nccl unknown, assuming `cpu` and `cuda`. You can specify it in `device:backend` format in `init_process_group` call.
  warnings.warn(
Traceback (most recent call last):
  File "../scripts/pretrain_wav2vec2.py", line 133, in <module>
    dist.init_process_group(backend="gloo|nccl")
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 89, in wrapper
    func_return = func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1312, in init_process_group
    default_pg, _ = _new_process_group_helper(
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1544, in _new_process_group_helper
    assert backend_str.upper() in Backend._plugins, (
AssertionError: Unknown c10d backend type GLOO|NCCL
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:326: UserWarning: Device capability of gloo|nccl unknown, assuming `cpu` and `cuda`. You can specify it in `device:backend` format in `init_process_group` call.
  warnings.warn(
Traceback (most recent call last):
  File "../scripts/pretrain_wav2vec2.py", line 133, in <module>
    dist.init_process_group(backend="gloo|nccl")
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 89, in wrapper
    func_return = func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1312, in init_process_group
    default_pg, _ = _new_process_group_helper(
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1544, in _new_process_group_helper
    assert backend_str.upper() in Backend._plugins, (
AssertionError: Unknown c10d backend type GLOO|NCCL
num_proc        : 2
Process rank: 3
World size: 4
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:326: UserWarning: Device capability of gloo|nccl unknown, assuming `cpu` and `cuda`. You can specify it in `device:backend` format in `init_process_group` call.
  warnings.warn(
Traceback (most recent call last):
  File "../scripts/pretrain_wav2vec2.py", line 133, in <module>
    dist.init_process_group(backend="gloo|nccl")
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
    return func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 89, in wrapper
    func_return = func(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1312, in init_process_group
    default_pg, _ = _new_process_group_helper(
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1544, in _new_process_group_helper
    assert backend_str.upper() in Backend._plugins, (
AssertionError: Unknown c10d backend type GLOO|NCCL
E0721 13:31:36.645610 47563838693056 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 104812) of binary: /home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/bin/python
Traceback (most recent call last):
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/run.py", line 879, in main
    run(args)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../scripts/pretrain_wav2vec2.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-07-21_13:31:36
  host      : gilbreth-c002.rcac.purdue.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 104813)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-07-21_13:31:36
  host      : gilbreth-c002.rcac.purdue.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 104814)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-07-21_13:31:36
  host      : gilbreth-c002.rcac.purdue.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 104815)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-21_13:31:36
  host      : gilbreth-c002.rcac.purdue.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 104812)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
