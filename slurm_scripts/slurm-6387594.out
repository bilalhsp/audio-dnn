gilbreth-c002.rcac.purdue.edu
Total tasks: 4
Total tasks per node: 4
CPUs per task: 2
CUDA visible devices: 0,1,2,3
Number of nodes: 1
The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/1.1.2
Process rank: 3
Local rank: 3
World size: 4
num_proc        : 2
batch_size      : 32
num_epochs      : 1
Process rank: 2
Local rank: 2
World size: 4
num_proc        : 2
batch_size      : 32
num_epochs      : 1
Process rank: 1
Local rank: 1
World size: 4
num_proc        : 2
batch_size      : 32
num_epochs      : 1
Process rank: 0
Local rank: 0
World size: 4
num_proc        : 2
batch_size      : 32
num_epochs      : 1
gilbreth-c002:125136:125136 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125136:125136 [0] NCCL INFO Bootstrap : Using ib0:172.18.36.32<0>
gilbreth-c002:125136:125136 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gilbreth-c002:125136:125136 [0] NCCL INFO cudaDriverVersion 12030
NCCL version 2.20.5+cuda11.0
gilbreth-c002:125138:125138 [2] NCCL INFO cudaDriverVersion 12030
gilbreth-c002:125138:125138 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125138:125138 [2] NCCL INFO Bootstrap : Using ib0:172.18.36.32<0>
gilbreth-c002:125138:125138 [2] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gilbreth-c002:125136:125199 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125136:125199 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ib0:172.18.36.32<0>
gilbreth-c002:125136:125199 [0] NCCL INFO Using non-device net plugin version 0
gilbreth-c002:125136:125199 [0] NCCL INFO Using network IB
gilbreth-c002:125139:125139 [3] NCCL INFO cudaDriverVersion 12030
gilbreth-c002:125139:125139 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125139:125139 [3] NCCL INFO Bootstrap : Using ib0:172.18.36.32<0>
gilbreth-c002:125139:125139 [3] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gilbreth-c002:125137:125137 [1] NCCL INFO cudaDriverVersion 12030
gilbreth-c002:125137:125137 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125137:125137 [1] NCCL INFO Bootstrap : Using ib0:172.18.36.32<0>
gilbreth-c002:125137:125137 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gilbreth-c002:125139:125205 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125139:125205 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ib0:172.18.36.32<0>
gilbreth-c002:125139:125205 [3] NCCL INFO Using non-device net plugin version 0
gilbreth-c002:125139:125205 [3] NCCL INFO Using network IB
gilbreth-c002:125137:125206 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125137:125206 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ib0:172.18.36.32<0>
gilbreth-c002:125137:125206 [1] NCCL INFO Using non-device net plugin version 0
gilbreth-c002:125137:125206 [1] NCCL INFO Using network IB
gilbreth-c002:125138:125209 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-c002:125138:125209 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ib0:172.18.36.32<0>
gilbreth-c002:125138:125209 [2] NCCL INFO Using non-device net plugin version 0
gilbreth-c002:125138:125209 [2] NCCL INFO Using network IB
gilbreth-c002:125136:125199 [0] NCCL INFO comm 0x563d0ee14c00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 61000 commId 0x4365217e6d901782 - Init START
gilbreth-c002:125137:125206 [1] NCCL INFO comm 0x55587b007400 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 62000 commId 0x4365217e6d901782 - Init START
gilbreth-c002:125138:125209 [2] NCCL INFO comm 0x565143d3f2f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 89000 commId 0x4365217e6d901782 - Init START
gilbreth-c002:125139:125205 [3] NCCL INFO comm 0x55e15abf5f70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 8a000 commId 0x4365217e6d901782 - Init START
gilbreth-c002:125136:125199 [0] NCCL INFO Setting affinity for GPU 0 to 03ff
gilbreth-c002:125139:125205 [3] NCCL INFO Setting affinity for GPU 3 to 0ffc00
gilbreth-c002:125138:125209 [2] NCCL INFO Setting affinity for GPU 2 to 0ffc00
gilbreth-c002:125137:125206 [1] NCCL INFO Setting affinity for GPU 1 to 03ff
gilbreth-c002:125136:125199 [0] NCCL INFO comm 0x563d0ee14c00 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 00/12 :    0   1   2   3
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 01/12 :    0   1   3   2
gilbreth-c002:125139:125205 [3] NCCL INFO comm 0x55e15abf5f70 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 02/12 :    0   2   3   1
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 03/12 :    0   2   1   3
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 04/12 :    0   3   1   2
gilbreth-c002:125138:125209 [2] NCCL INFO comm 0x565143d3f2f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 05/12 :    0   3   2   1
gilbreth-c002:125137:125206 [1] NCCL INFO comm 0x55587b007400 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 06/12 :    0   1   2   3
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 07/12 :    0   1   3   2
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 08/12 :    0   2   3   1
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 09/12 :    0   2   1   3
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 10/12 :    0   3   1   2
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 11/12 :    0   3   2   1
gilbreth-c002:125139:125205 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->1 [3] -1/-1/-1->3->1 [4] 2/-1/-1->3->0 [5] 2/-1/-1->3->0 [6] -1/-1/-1->3->2 [7] -1/-1/-1->3->2 [8] -1/-1/-1->3->1 [9] -1/-1/-1->3->1 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0
gilbreth-c002:125139:125205 [3] NCCL INFO P2P Chunksize set to 524288
gilbreth-c002:125136:125199 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 2/-1/-1->0->-1 [3] 2/-1/-1->0->-1 [4] 3/-1/-1->0->1 [5] 3/-1/-1->0->1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 2/-1/-1->0->-1 [9] 2/-1/-1->0->-1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1
gilbreth-c002:125136:125199 [0] NCCL INFO P2P Chunksize set to 524288
gilbreth-c002:125138:125209 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 1/-1/-1->2->0 [3] 1/-1/-1->2->0 [4] -1/-1/-1->2->3 [5] -1/-1/-1->2->3 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 1/-1/-1->2->0 [9] 1/-1/-1->2->0 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3
gilbreth-c002:125138:125209 [2] NCCL INFO P2P Chunksize set to 524288
gilbreth-c002:125137:125206 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 3/-1/-1->1->2 [3] 3/-1/-1->1->2 [4] 0/-1/-1->1->-1 [5] 0/-1/-1->1->-1 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 3/-1/-1->1->2 [9] 3/-1/-1->1->2 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1
gilbreth-c002:125137:125206 [1] NCCL INFO P2P Chunksize set to 524288
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Connected all rings
gilbreth-c002:125138:125209 [2] NCCL INFO Connected all rings
gilbreth-c002:125137:125206 [1] NCCL INFO Connected all rings
gilbreth-c002:125136:125199 [0] NCCL INFO Connected all rings
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 04/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125136:125199 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 05/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 10/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 11/0 : 3[3] -> 0[0] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 02/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 08/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 03/0 : 3[3] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 02/0 : 1[1] -> 3[3] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 09/0 : 2[2] -> 0[0] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 09/0 : 3[3] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 08/0 : 1[1] -> 3[3] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125138:125209 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125137:125206 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/IPC
gilbreth-c002:125139:125205 [3] NCCL INFO Connected all trees
gilbreth-c002:125136:125199 [0] NCCL INFO Connected all trees
gilbreth-c002:125139:125205 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gilbreth-c002:125139:125205 [3] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 4 p2p channels per peer
gilbreth-c002:125138:125209 [2] NCCL INFO Connected all trees
gilbreth-c002:125136:125199 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gilbreth-c002:125136:125199 [0] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 4 p2p channels per peer
gilbreth-c002:125138:125209 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gilbreth-c002:125138:125209 [2] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 4 p2p channels per peer
gilbreth-c002:125137:125206 [1] NCCL INFO Connected all trees
gilbreth-c002:125137:125206 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gilbreth-c002:125137:125206 [1] NCCL INFO 12 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 4 p2p channels per peer
gilbreth-c002:125138:125209 [2] NCCL INFO comm 0x565143d3f2f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 89000 commId 0x4365217e6d901782 - Init COMPLETE
gilbreth-c002:125136:125199 [0] NCCL INFO comm 0x563d0ee14c00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 61000 commId 0x4365217e6d901782 - Init COMPLETE
gilbreth-c002:125139:125205 [3] NCCL INFO comm 0x55e15abf5f70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 8a000 commId 0x4365217e6d901782 - Init COMPLETE
gilbreth-c002:125137:125206 [1] NCCL INFO comm 0x55587b007400 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 62000 commId 0x4365217e6d901782 - Init COMPLETE
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/ahmedb/.cache/huggingface/token
Login successful
Login to hub successful...!
Token is valid (permission: fineGrained).
Token is valid (permission: fineGrained).
Your token has been saved to /home/ahmedb/.cache/huggingface/token
Login successful
Login to hub successful...!
Your token has been saved to /home/ahmedb/.cache/huggingface/token
Login successful
Login to hub successful...!
Token is valid (permission: fineGrained).
Your token has been saved to /home/ahmedb/.cache/huggingface/token
Login successful
Login to hub successful...!
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Starting training...!
Starting training...!
Starting training...!
Starting training...!
  0%|          | 0/66 [00:00<?, ?it/s][rank3]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank2]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank3]: Traceback (most recent call last):
[rank3]:   File "../scripts/pretrain_wav2vec2.py", line 151, in <module>
[rank3]:     train_wav2vec2(args)
[rank3]:   File "../scripts/pretrain_wav2vec2.py", line 108, in train_wav2vec2
[rank3]:     trainer.train()
[rank3]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 1923, in train
[rank3]:     return inner_training_loop(
[rank3]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 2268, in _inner_training_loop
[rank3]:     tr_loss_step = self.training_step(model, inputs)
[rank3]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 3324, in training_step
[rank3]:     self.accelerator.backward(loss, **kwargs)
[rank3]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/accelerator.py", line 2147, in backward
[rank3]:     self.scaler.scale(loss).backward(**kwargs)
[rank3]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
[rank3]:     torch.autograd.backward(
[rank3]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank3]:     _engine_run_backward(
[rank3]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank3]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank3]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.87 GiB. GPU  has a total capacity of 31.74 GiB of which 3.83 GiB is free. Including non-PyTorch memory, this process has 27.91 GiB memory in use. Of the allocated memory 26.90 GiB is allocated by PyTorch, and 192.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "../scripts/pretrain_wav2vec2.py", line 151, in <module>
[rank0]:     train_wav2vec2(args)
[rank0]:   File "../scripts/pretrain_wav2vec2.py", line 108, in train_wav2vec2
[rank0]:     trainer.train()
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 1923, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 2268, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 3324, in training_step
[rank0]:     self.accelerator.backward(loss, **kwargs)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/accelerator.py", line 2147, in backward
[rank0]:     self.scaler.scale(loss).backward(**kwargs)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 
[rank2]: Traceback (most recent call last):
[rank2]:   File "../scripts/pretrain_wav2vec2.py", line 151, in <module>
[rank2]:     train_wav2vec2(args)
[rank2]:   File "../scripts/pretrain_wav2vec2.py", line 108, in train_wav2vec2
[rank2]:     trainer.train()
[rank2]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 1923, in train
[rank2]:     return inner_training_loop(
[rank2]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 2268, in _inner_training_loop
[rank2]:     tr_loss_step = self.training_step(model, inputs)
[rank2]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 3324, in training_step
[rank2]:     self.accelerator.backward(loss, **kwargs)
[rank2]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/accelerator.py", line 2147, in backward
[rank2]:     self.scaler.scale(loss).backward(**kwargs)
[rank2]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
[rank2]:     torch.autograd.backward(
[rank2]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank2]:     _engine_run_backward(
[rank2]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank2]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank2]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.87 GiB. GPU  has a total capacity of 31.74 GiB of which 3.81 GiB is free. Including non-PyTorch memory, this process has 27.93 GiB memory in use. Of the allocated memory 26.89 GiB is allocated by PyTorch, and 186.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 0/66 [00:55<?, ?it/s]
[rank1]: Traceback (most recent call last):
[rank1]:   File "../scripts/pretrain_wav2vec2.py", line 151, in <module>
[rank1]:     train_wav2vec2(args)
[rank1]:   File "../scripts/pretrain_wav2vec2.py", line 108, in train_wav2vec2
[rank1]:     trainer.train()
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 1923, in train
[rank1]:     return inner_training_loop(
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 2268, in _inner_training_loop
[rank1]:     tr_loss_step = self.training_step(model, inputs)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/trainer.py", line 3324, in training_step
[rank1]:     self.accelerator.backward(loss, **kwargs)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/accelerator.py", line 2147, in backward
[rank1]:     self.scaler.scale(loss).backward(**kwargs)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
[rank1]:     torch.autograd.backward(
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank1]:     _engine_run_backward(
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.87 GiB. GPU  has a total capacity of 31.74 GiB of which 3.78 GiB is free. Including non-PyTorch memory, this process has 27.95 GiB memory in use. Of the allocated memory 26.90 GiB is allocated by PyTorch, and 186.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0721 15:21:42.764114 47478670827200 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 125137 closing signal SIGTERM
E0721 15:21:43.229840 47478670827200 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 125136) of binary: /home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/bin/python
Traceback (most recent call last):
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/run.py", line 879, in main
    run(args)
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../scripts/pretrain_wav2vec2.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-07-21_15:21:42
  host      : gilbreth-c002.rcac.purdue.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 125138)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-07-21_15:21:42
  host      : gilbreth-c002.rcac.purdue.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 125139)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-21_15:21:42
  host      : gilbreth-c002.rcac.purdue.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 125136)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
