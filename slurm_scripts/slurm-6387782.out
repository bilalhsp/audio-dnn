gilbreth-n000.rcac.purdue.edu
Total tasks: 2
Total tasks per node: 2
CPUs per task: 4
CUDA visible devices: 0,1
Number of nodes: 1
The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) xalt/1.1.2
Process rank: 1Process rank: 0

Local rank: 1Local rank: 0

World size: 2World size: 2

num_proc        : 4num_proc        : 4

batch_size      : 16batch_size      : 16

num_epochs      : 100num_epochs      : 100

num_tasks       : 2num_tasks       : 2

gilbreth-n000:84628:84628 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-n000:84628:84628 [0] NCCL INFO Bootstrap : Using ib0:172.18.36.153<0>
gilbreth-n000:84628:84628 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gilbreth-n000:84628:84628 [0] NCCL INFO cudaDriverVersion 12030
NCCL version 2.20.5+cuda11.0
gilbreth-n000:84628:84671 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-n000:84628:84671 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ib0:172.18.36.153<0>
gilbreth-n000:84628:84671 [0] NCCL INFO Using non-device net plugin version 0
gilbreth-n000:84628:84671 [0] NCCL INFO Using network IB
gilbreth-n000:84629:84629 [1] NCCL INFO cudaDriverVersion 12030
gilbreth-n000:84629:84629 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-n000:84629:84629 [1] NCCL INFO Bootstrap : Using ib0:172.18.36.153<0>
gilbreth-n000:84629:84629 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gilbreth-n000:84629:84675 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker,eth,lo
gilbreth-n000:84629:84675 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [RO]; OOB ib0:172.18.36.153<0>
gilbreth-n000:84629:84675 [1] NCCL INFO Using non-device net plugin version 0
gilbreth-n000:84629:84675 [1] NCCL INFO Using network IB
gilbreth-n000:84629:84675 [1] NCCL INFO comm 0x563469fca640 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId c1000 commId 0x243e403c6e831613 - Init START
gilbreth-n000:84628:84671 [0] NCCL INFO comm 0x55c681f1a0b0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 41000 commId 0x243e403c6e831613 - Init START
gilbreth-n000:84629:84675 [1] NCCL INFO comm 0x563469fca640 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
gilbreth-n000:84628:84671 [0] NCCL INFO comm 0x55c681f1a0b0 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 00/08 :    0   1
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 01/08 :    0   1
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 02/08 :    0   1
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 03/08 :    0   1
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 04/08 :    0   1
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 05/08 :    0   1
gilbreth-n000:84629:84675 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 0/-1/-1->1->-1 [3] 0/-1/-1->1->-1 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 06/08 :    0   1
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 07/08 :    0   1
gilbreth-n000:84629:84675 [1] NCCL INFO P2P Chunksize set to 524288
gilbreth-n000:84628:84671 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1
gilbreth-n000:84628:84671 [0] NCCL INFO P2P Chunksize set to 524288
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/IPC/read
gilbreth-n000:84629:84675 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/IPC/read
gilbreth-n000:84628:84671 [0] NCCL INFO Connected all rings
gilbreth-n000:84628:84671 [0] NCCL INFO Connected all trees
gilbreth-n000:84629:84675 [1] NCCL INFO Connected all rings
gilbreth-n000:84629:84675 [1] NCCL INFO Connected all trees
gilbreth-n000:84629:84675 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
gilbreth-n000:84629:84675 [1] NCCL INFO 8 coll channels, 0 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
gilbreth-n000:84628:84671 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
gilbreth-n000:84628:84671 [0] NCCL INFO 8 coll channels, 0 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
gilbreth-n000:84628:84671 [0] NCCL INFO comm 0x55c681f1a0b0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 41000 commId 0x243e403c6e831613 - Init COMPLETE
gilbreth-n000:84629:84675 [1] NCCL INFO comm 0x563469fca640 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId c1000 commId 0x243e403c6e831613 - Init COMPLETE
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/ahmedb/.cache/huggingface/token
Login successful
Login to hub successful...!
gradient accumulation steps: 20.0
saving every 0.005th step...
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/ahmedb/.cache/huggingface/token
Login successful
Login to hub successful...!
gradient accumulation steps: 20.0
saving every 0.005th step...
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 306, in _lazy_init
[rank1]:     queued_call()
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 174, in _check_capability
[rank1]:     capability = get_device_capability(d)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 430, in get_device_capability
[rank1]:     prop = get_device_properties(device)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 448, in get_device_properties
[rank1]:     return _get_device_properties(device)  # type: ignore[name-defined]
[rank1]: RuntimeError: CUDA error: unknown error
[rank1]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank1]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[rank1]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[rank1]: The above exception was the direct cause of the following exception:

[rank1]: Traceback (most recent call last):
[rank1]:   File "../scripts/pretrain_wav2vec2.py", line 176, in <module>
[rank1]:     train_wav2vec2(args)
[rank1]:   File "../scripts/pretrain_wav2vec2.py", line 68, in train_wav2vec2
[rank1]:     training_args = TrainingArguments(
[rank1]:   File "<string>", line 129, in __init__
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py", line 1693, in __post_init__
[rank1]:     self.device
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py", line 2171, in device
[rank1]:     return self._setup_devices
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/utils/generic.py", line 60, in __get__
[rank1]:     cached = self.fget(obj)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py", line 2108, in _setup_devices
[rank1]:     self.distributed_state = PartialState(**accelerator_state_kwargs)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/state.py", line 280, in __init__
[rank1]:     self.set_device()
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/state.py", line 790, in set_device
[rank1]:     torch.cuda.set_device(self.device)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 399, in set_device
[rank1]:     torch._C._cuda_setDevice(device)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 312, in _lazy_init
[rank1]:     raise DeferredCudaCallError(msg) from e
[rank1]: torch.cuda.DeferredCudaCallError: CUDA call failed lazily at initialization with error: CUDA error: unknown error
[rank1]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank1]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[rank1]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[rank1]: CUDA call was originally invoked at:

[rank1]:   File "../scripts/pretrain_wav2vec2.py", line 7, in <module>
[rank1]:     from transformers import TrainingArguments, Trainer
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank1]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/__init__.py", line 26, in <module>
[rank1]:     from . import dependency_versions_check
[rank1]:   File "<frozen importlib._bootstrap>", line 1042, in _handle_fromlist
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank1]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 16, in <module>
[rank1]:     from .utils.versions import require_version, require_version_core
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank1]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/utils/__init__.py", line 34, in <module>
[rank1]:     from .generic import (
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank1]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/utils/generic.py", line 462, in <module>
[rank1]:     import torch.utils._pytree as _torch_pytree
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank1]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/__init__.py", line 1480, in <module>
[rank1]:     _C._initExtension(manager_path())
[rank1]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank1]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank1]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank1]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank1]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 238, in <module>
[rank1]:     _lazy_call(_check_capability)
[rank1]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 235, in _lazy_call
[rank1]:     _queued_calls.append((callable, traceback.format_stack()))

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 306, in _lazy_init
[rank0]:     queued_call()
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 174, in _check_capability
[rank0]:     capability = get_device_capability(d)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 430, in get_device_capability
[rank0]:     prop = get_device_properties(device)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 448, in get_device_properties
[rank0]:     return _get_device_properties(device)  # type: ignore[name-defined]
[rank0]: RuntimeError: CUDA error: unknown error
[rank0]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank0]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[rank0]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "../scripts/pretrain_wav2vec2.py", line 176, in <module>
[rank0]:     train_wav2vec2(args)
[rank0]:   File "../scripts/pretrain_wav2vec2.py", line 68, in train_wav2vec2
[rank0]:     training_args = TrainingArguments(
[rank0]:   File "<string>", line 129, in __init__
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py", line 1693, in __post_init__
[rank0]:     self.device
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py", line 2171, in device
[rank0]:     return self._setup_devices
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/utils/generic.py", line 60, in __get__
[rank0]:     cached = self.fget(obj)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/training_args.py", line 2108, in _setup_devices
[rank0]:     self.distributed_state = PartialState(**accelerator_state_kwargs)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/state.py", line 280, in __init__
[rank0]:     self.set_device()
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/accelerate/state.py", line 790, in set_device
[rank0]:     torch.cuda.set_device(self.device)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 399, in set_device
[rank0]:     torch._C._cuda_setDevice(device)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 312, in _lazy_init
[rank0]:     raise DeferredCudaCallError(msg) from e
[rank0]: torch.cuda.DeferredCudaCallError: CUDA call failed lazily at initialization with error: CUDA error: unknown error
[rank0]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank0]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
[rank0]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


[rank0]: CUDA call was originally invoked at:

[rank0]:   File "../scripts/pretrain_wav2vec2.py", line 7, in <module>
[rank0]:     from transformers import TrainingArguments, Trainer
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank0]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/__init__.py", line 26, in <module>
[rank0]:     from . import dependency_versions_check
[rank0]:   File "<frozen importlib._bootstrap>", line 1042, in _handle_fromlist
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank0]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 16, in <module>
[rank0]:     from .utils.versions import require_version, require_version_core
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank0]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/utils/__init__.py", line 34, in <module>
[rank0]:     from .generic import (
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank0]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/utils/generic.py", line 462, in <module>
[rank0]:     import torch.utils._pytree as _torch_pytree
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank0]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/__init__.py", line 1480, in <module>
[rank0]:     _C._initExtension(manager_path())
[rank0]:   File "<frozen importlib._bootstrap>", line 991, in _find_and_load
[rank0]:   File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
[rank0]:   File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
[rank0]:   File "<frozen importlib._bootstrap_external>", line 783, in exec_module
[rank0]:   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 238, in <module>
[rank0]:     _lazy_call(_check_capability)
[rank0]:   File "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/cuda/__init__.py", line 235, in _lazy_call
[rank0]:     _queued_calls.append((callable, traceback.format_stack()))

slurmstepd: error: *** JOB 6387782 ON gilbreth-n000 CANCELLED AT 2024-07-21T20:16:25 ***
slurmstepd: error: *** JOB 6387782 STEPD TERMINATED ON gilbreth-n000 AT 2024-07-21T20:20:35 DUE TO JOB NOT ENDING WITH SIGNALS ***
slurmstepd: error: Container 84563 in cgroup plugin has 2 processes, giving up after 255 sec
